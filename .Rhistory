ggplot(data=oldFaithfulData, aes(y=Minutes.between.eruptions,x=Duration.of.eruption))+ geom_point(shape=16) +    # Use round circles
)
ggplot(data=oldFaithfulData, aes(y=Minutes.between.eruptions,x=Duration.of.eruption))
+ geom_point(shape=16)  # Use round circles
+ geom_smooth(method=lm)# Add linear regression line
#  (by default includes 95% confidence region)
ggplot(data=oldFaithfulData, aes(y=Duration.of.eruption,x=Minutes.between.eruptions))
+ geom_point(shape=16)  # Use round circles
+ geom_smooth(method=lm)# Add linear regression line
#  (by default includes 95% confidence region)
qplot(data=oldFaithfulData, x=Minutes.between.eruptions, y=Duration.of.eruption)
+ abline(lm(Duration.of.eruption~Minutes.between.eruptions), col="red") # regression line (y~x)
abline(lm(Duration.of.eruption~Minutes.between.eruptions), col="red") # regression line (y~x)
duration=oldFaithfulData$Duration.of.eruption
minutes=oldFaithfulData$Minutes.between.eruptions
plot(duration, minutes)
plot(duration, minutes + ylab="Minute Intervals")
plot(duration, minutes, + ylab="Minute Intervals")
plot(duration, minutes, + ylab = "Minute Intervals")
plot(duration, minutes)
abline(lm(duration ~ minutes))
plot(duration, minutes)+
abline(lm(duration ~ minutes))
?faithful
faithful
library(faithful)
duration = faithful$eruptions
waiting = faithful$waiting
head(cbind(duration, waiting))
plot(duration, waiting,            # plot the variables
+   xlab="Eruption duration",        # x−axis label
+   ylab="Time waited")
plot(duration, waiting)
abline(lm(waiting ~ duration))
plot(duration, minutes)
minutes=oldFaithfulData$Minutes.between.eruptions
oldFaithfulData <- read.csv("~/Documents/R/oldFaithfulData.csv")
View(oldFaithfulData)
minutes=oldFaithfulData$Minutes.between.eruptions
plot(duration, minutes)
duration=oldFaithfulData$Duration.of.eruption
plot(duration, minutes)
abline(lm(minutes ~ duration))
convertlm<-lm(minutes ~ duration)
summary(convertlm)$r.squared
eruptionlm<-lm(minutes ~ duration)
summary(eruptionlm)
library(xlsx)
gd<-read.xlsx("gd.xlsx", sheetIndex=1, header=TRUE, colClasses=NA)
str(gd)
library(ggplot2)
ggplot(data=gd, aes(y=convert.rate,x=pages.session))+ geom_point(shape=16) +    # Use round circles
geom_smooth(method=lm)# Add linear regression line
#  (by default includes 95% confidence region)
cor(gd$pages.session,gd$convert.rate)
cor.test(gd$pages.session, gd$convert.rate)
convertlm<-lm(pages.session ~ convert.rate, data=gd)
summary(convertlm)$r.squared
vars<-c("pages.session", "convert.rate")
round(cor(gd[,vars]), digits = 3)
ggplot(data=gd, aes(x=avg.sess.dur,y=convert.rate)) + geom_point(shape=1) + geom_smooth(method=lm) + scale_fill_gradient( low = "red",high = "yellow")
read.csv('oldfaithfuldata.csv', header=TRUE, sep=',')
str(oldFaithfulData)
oldFaithfulData<-read.csv('oldfaithfuldata.csv', header=TRUE, sep=',')
duration=oldFaithfulData$Duration.of.eruption
minutes=oldFaithfulData$Minutes.between.eruptions
library(ggplot2)
plot(duration, minutes)
abline(lm(minutes ~ duration))
eruptionlm<-lm(minutes ~ duration)
summary(eruptionlm)$r.squared
ggplot(data=oldFaithfulData, aes(y=Duration.of.eruption,x=Minutes.between.eruptions))
+ geom_point(shape=16)  # Use round circles
+ geom_smooth(method=lm)# Add linear regression line
#  (by default includes 95% confidence region)
hist(oldFaithfulData)
hist(duration)
hist(eruptionlm)
hist(minutes)
?open
module0 <- read.csv("~/Documents/R/module0.R", comment.char="#")
View(module0)
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
head(data)
summary(data)
View(data)
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$year_of_purchase = as.numeric(format(data$date_of_purchase, "%Y"))
View(data)
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$year_of_purchase = as.numeric(format(data$date_of_purchase, "%Y"))
View(data)
library(sqldf)
x = sqldf("SELECT year_of_purchase, COUNT(year_of_purchase) AS 'counter' FROM data GROUP BY 1 ORDER BY 1")
barplot(x$counter, names.arg = x$year_of_purchase)
x = sqldf("SELECT year_of_purchase, COUNT(year_of_purchase) AS 'counter' FROM data GROUP BY 1 ORDER BY 1")
library(sqldf)
install.packages("sqldf")
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$days_since       = as.numeric(difftime(time1 = "2016-01-01",
time2 = data$date_of_purchase,
units = "days"))
head(data)
summary(data)
library(sqldf)
customers = sqldf("SELECT customer_id,
MIN(days_since) AS 'recency',
COUNT(*) AS 'frequency',
AVG(purchase_amount) AS 'amount'
FROM data GROUP BY 1")
View(customers)
head(customers)
summary(customers)
hist(customers$recency)
hist(customers$frequency)
hist(customers$amount)
hist(customers$amount, breaks = 100)
new_data = customers
View(new_data)
head(new_data)
row.names(new_data) = new_data$customer_id
new_data$customer_id = NULL
head(new_data)
View(new_data)
new_data$amount = log(new_data$amount)
hist(new_data$amount)
new_data = scale(new_data)
head(new_data)
View(new_data)
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$days_since       = as.numeric(difftime(time1 = "2016-01-01",
time2 = data$date_of_purchase,
units = "days"))
library(sqldf)
customers = sqldf("SELECT customer_id,
MIN(days_since) AS 'recency',
COUNT(*) AS 'frequency',
AVG(purchase_amount) AS 'amount'
FROM data GROUP BY 1")
head(customers)
summary(customers)
hist(customers$recency)
hist(customers$frequency)
hist(customers$amount)
hist(customers$amount, breaks = 100)
View(customers)
View(data)
dates<-as.vector(data['date_of_purchase'])
View(dates)
class(dates)
dates1<-dates[,'date_of_purchase']
class(dates1)
dates1<-dates[['date_of_purchase']]
class(dates1)
dates<-as.vector(data['date_of_purchase'])
class(dates)
View(dates)
min(dates$date_of_purchase)
max(data$date_of_purchase)
head(customers)
summary(customers)
hist(customers$amount, breaks = 200)
customers_2015 = sqldf("SELECT customer_id,
MIN(days_since) AS 'recency',
MAX(days_since) AS 'first_purchase',
COUNT(*) AS 'frequency',
AVG(purchase_amount) AS 'amount'
FROM data GROUP BY 1")
head(customers_2015)
summary(customers_2015)
hist(customers_2015$recency)
hist(customers_2015$frequency)
hist(customers_2015$amount)
hist(customers_2015$amount, breaks = 100)
ifelse?
?
stop()
customers_2015$segment = ifelse(test = customers_2015$recency > 365*3, yes = "inactive", no = "NA")
table(customers_2015$segment)
aggregate(x = customers_2015[, 2:5], by = list(customers_2015$segment), mean)
View(customers_2015)
x <- 5
if(x > 0){
print("Positive number")
}
x <- 0
if(x > 0){
print("Positive number")
}
x <- -5
if(x > 0){
print("Non-negative number")
} else {
print("Negative number")
}
# Simple 2-segment solution based on recency alone
customers_2015$segment = ifelse(test = customers_2015$recency > 365*3, yes = "inactive", no = "NA")
table(customers_2015$segment)
aggregate(x = customers_2015[, 2:5], by = list(customers_2015$segment), mean)
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
# Add headers and interpret the last column as a date, extract year of purchase
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$days_since       = as.numeric(difftime(time1 = "2016-01-01",
time2 = data$date_of_purchase,
units = "days"))
# Display the data after transformation
head(data)
summary(data)
# Compute key marketing indicators using SQL language
library(sqldf)
# Compute recency, frequency, and average purchase amount
customers = sqldf("SELECT customer_id,
MIN(days_since) AS 'recency',
COUNT(*) AS 'frequency',
AVG(purchase_amount) AS 'amount'
FROM data GROUP BY 1")
# Explore the data
head(customers)
summary(customers)
hist(customers$recency)
hist(customers$frequency)
hist(customers$amount)
hist(customers$amount, breaks = 100)
hist(customers$amount, breaks = 200)
#my own notes
#turns date column into a data frame of its own
dates<-as.vector(data['date_of_purchase'])
class(dates)
#earliest purchase date
min(dates$date_of_purchase)
#most recent purchase chate
max(data$date_of_purchase)
new_data = customers
head(new_data)
row.names(new_data) = new_data$customer_id
new_data$customer_id = NULL
head(new_data)
row.names(new_data) = new_data$customer_id
new_data$customer_id = NULL
head(new_data)
View(new_data)
new_data = customers
View(new_data)
row.names(new_data) = new_data$customer_id
View(new_data)
new_data$customer_id = NULL
View(new_data)
Kloutscores1 <- read.table("~/Documents/R/Kloutscores1.csv", quote="\"", comment.char="")
View(Kloutscores1)
`colnames<-`(Kloutscores1$V1)
`colnames<-`(Kloutscores1)
rownames(Kloutscores1) <- c(“Granny”)
rownames(Kloutscores1) <- “Granny”
rownames(Kloutscores1) <- Granny
rownames(Kloutscores1)
colnames(Kloutscores1)
colnames(Kloutscores1)[1]<-"score"
colnames(Kloutscores1)
colnames(Kloutscores1)=Kloutscores1$score
Kloutscores1$score=NULL
colnames(Kloutscores1)
View(Kloutscores1)
Kloutscores1 <- read.table("~/Documents/R/Kloutscores1.csv", quote="\"", comment.char="")
View(Kloutscores1)
list(Kloutscores1$V1)
new_list<-list(Kloutscores1$V1)
sum(new_list)
library(devtools)
install_version("colorspace", "1.2-4")
View(new_data)
new_data$amount = log(new_data$amount)
hist(new_data$amount)
new_data = scale(new_data)
head(new_data)
View(new_data)
5000-400
4600/50
5000*.235
5000*.0235
100-2.35
95+2.35
sample = seq(1, 18417, by = 10)
head(sample)
customers_sample = customers[sample, ]
View(customers_sample)
new_data_sample  = new_data[sample, ]
d = dist(new_data_sample)
d <- dist(as.matrix(mtcars))   # find distance matrix
hc <- hclust(d)                # apply hirarchical clustering
plot(hc)
e<- dist(as.matrix(Kloutscores1))
kloutCluster<-hclust(e)
plot(kloutCluster)
d = dist(new_data_sample)
c = hclust(d, method="ward.D2")
plot(c)
members = cutree(c, k = 9)
members[1:30]
table(members)
aggregate(customers_sample[, 2:4], by = list(members), mean)
z <- dist(mydata, method = "euclidean") # distance matrix
fit <- hclust(z, method="ward")
plot(fit) # display dendogram
groups <- cutree(fit, k=5) # cut tree into 5 clusters
# draw dendogram with red borders around the 5 clusters
rect.hclust(fit, k=5, border="red")
z <- dist(mydata, method = "euclidean") # distance matrix
mydata <- scale(mtcars) # standardize variables
z <- dist(mydata, method = "euclidean") # distance matrix
fit <- hclust(z, method="ward")
plot(fit) # display dendogram
groups <- cutree(fit, k=5) # cut tree into 5 clusters
rect.hclust(fit, k=5, border="red")
plot(c)
table(members)
install.packages("devtools")
install_github("ozagordi/weatherData")
devtools::install_github("ozagordi/weatherData")
end_date="2016-08-27")
weatherdata <- getWeatherForDate("BOS", "2016-08-01",
end_date="2016-08-15")
weatherdata <- getWeatherForDate("BOS", "2016-08-01", end_date="2016-08-15")
library(weatherData)
getWeatherForDate("SEA", "2014-05-05")
dfw_wx <- getWeatherForYear("DFW", 2013)
jax_wx <- getWeatherForYear("JAX", 2016)
city1 <- "ORD"
city2 <- "SFO"
df1 <- getWeatherForYear(city1, 2013)
df2 <- getWeatherForYear(city2, 2013)
getDailyDifferences <- function(df1, df2){
Delta_Means <- df1$Mean_TemperatureF - df2$Mean_TemperatureF
Delta_Max <- df1$Max_TemperatureF - df2$Max_TemperatureF
Delta_Min <- df1$Min_TemperatureF - df2$Min_TemperatureF
diff_df <- data.frame(Date=df1$Date, Delta_Means, Delta_Max, Delta_Min)
return(diff_df)
}
plotDifferences <- function (differences, city1, city2) {
library(reshape2)
m.diff <- melt(differences, id.vars=c("Date"))
p <- ggplot(m.diff, aes(x=Date, y=value)) + geom_point(aes(color=variable)) +
facet_grid(variable ~ .) +geom_hline(yintercept=0)
p <- p + labs(title=paste0("Daily Temperature Differences: ", city1, " minus ",city2))
print(p)
}
differences<- getDailyDifferences(df1, df2)
plotDifferences(differences, city1, city2)
aggregate(customers_sample[, 2:4], by = list(members), mean)
table(members)
aggregate(customers_sample[, 2:4], by = list(members), mean)
# Load text file into local variable called 'data'
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
# Add headers and interpret the last column as a date, extract year of purchase
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$days_since       = as.numeric(difftime(time1 = "2016-01-01",
time2 = data$date_of_purchase,
units = "days"))
library(sqldf)
customers = sqldf("SELECT customer_id,
MIN(days_since) AS 'recency',
COUNT(*) AS 'frequency',
AVG(purchase_amount) AS 'amount'
FROM data GROUP BY 1")
# Copy customer data into new data frame/carbon copy
new_data = customers
row.names(new_data) = new_data$customer_id
new_data$customer_id = NULL
hist(customers$frequency)
hist(new_data$frequency)
new_data$frequency=log(new_data$frequency)
hist(new_data$frequency)
hist(new_data$frequency, y="log of frequency")
hist(new_data$frequency, main="histogram of new_data with log of frequency")
new_data = scale(new_data)
sample = seq(1, 18417, by = 10)
head(sample)
customers_sample = customers[sample, ]
new_data_sample  = new_data[sample, ]
View(new_data_sample)
dim(customers)
# Compute distance metrics on standardized data
d = dist(new_data_sample)
# Perform hierarchical clustering on distance metrics
c = hclust(d, method="ward.D2")
# Plot de dendogram
plot(c)
members = cutree(c, k = 5)
members[1:5]
table(members)
aggregate(customers_sample[, 2:4], by = list(members), mean)
View(new_data_sample)
new_data_sample[c(260,5920)]
new_data_sample[c(260,5920),]
new_data_sample[260,]
new_data_sample[5920,]
new_data_sample["5920"]
new_data_sample[2700,]
table(members)
aggregate(customers_sample[, 2:4], by = list(members), mean)
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$days_since       = as.numeric(difftime(time1 = "2016-01-01",
time2 = data$date_of_purchase,
units = "days"))
library(sqldf)
customers = sqldf("SELECT customer_id,
MIN(days_since) AS 'recency',
COUNT(*) AS 'frequency',
AVG(purchase_amount) AS 'amount'
FROM data GROUP BY 1")
# Copy customer data into new data frame
new_data = customers
row.names(new_data) = new_data$customer_id
new_data$customer_id = NULL
new_data$frequency=log(new_data$frequency)
hist(new_data$frequency, main="histogram of new_data with log of frequency")
new_data = scale(new_data)
sample = seq(1, 18417, by = 10)
head(sample)
customers_sample = customers[sample, ]
new_data_sample  = new_data[sample, ]
d = dist(new_data_sample)
c = hclust(d, method="ward.D2")
plot(c)
members = cutree(c, k = 5)
members[1:5]
table(members)
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$days_since       = as.numeric(difftime(time1 = "2016-01-01",
time2 = data$date_of_purchase,
units = "days"))
library(sqldf)
customers = sqldf("SELECT customer_id,
MIN(days_since) AS 'recency',
COUNT(*) AS 'frequency',
AVG(purchase_amount) AS 'amount'
FROM data GROUP BY 1")
new_data = customers
row.names(new_data) = new_data$customer_id
new_data$customer_id = NULL
View(new_data)
hist(new_data$frequency)
new_data$frequency=log(new_data$frequency)
hist(new_data$frequency, main="histogram of new_data with log of frequency")
new_data = scale(new_data)
sample = seq(1, 18417, by = 10)
head(sample)
customers_sample = customers[sample, ]
new_data_sample  = new_data[sample, ]
d = dist(new_data_sample)
c = hclust(d, method="ward.D2")
plot(c)
members = cutree(c, k = 5)
members[1:30]
table(members)
aggregate(customers_sample[, 2:4], by = list(members), mean)
members = cutree(c, k = 9)
members[1:30]
table(members)
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$days_since       = as.numeric(difftime(time1 = "2016-01-01",
time2 = data$date_of_purchase,
units = "days"))
customers = sqldf("SELECT customer_id,
MIN(days_since) AS 'recency',
COUNT(*) AS 'frequency',
AVG(purchase_amount) AS 'amount'
FROM data GROUP BY 1")
View(data)
new_data = customers
row.names(new_data) = new_data$customer_id
new_data$customer_id = NULL
new_data$amount = log(new_data$amount)
hist(new_data$amount)
hist(new_data$frequency)
new_data$frequency=log(new_data$frequency)
hist(new_data$frequency, main="histogram of new_data with log of frequency")
new_data = scale(new_data)
sample = seq(1, 18417, by = 10)
head(sample)
customers_sample = customers[sample, ]
new_data_sample  = new_data[sample, ]
# Compute distance metrics on standardized data
d = dist(new_data_sample)
# Perform hierarchical clustering on distance metrics
c = hclust(d, method="ward.D2")
# Plot de dendogram
plot(c)
# Cut at 5 segments
members = cutree(c, k = 5)
# Show 30 first customers, frequency table
members[1:30]
table(members)
# Show profile of each segment
aggregate(customers_sample[, 2:4], by = list(members), mean)
new_data_sample[c(260,5920),]
new_data_sample[260,]
View(new_data_sample)
