summary(data)
# Compute key marketing indicators using SQL language
library(sqldf)
# Compute recency, frequency, and average purchase amount
customers = sqldf("SELECT customer_id,
MIN(days_since) AS 'recency',
COUNT(*) AS 'frequency',
AVG(purchase_amount) AS 'amount'
FROM data GROUP BY 1")
# Explore the data
head(customers)
summary(customers)
hist(customers$recency)
hist(customers$frequency)
hist(customers$amount)
hist(customers$amount, breaks = 100)
hist(customers$amount, breaks = 200)
#my own notes
#turns date column into a data frame of its own
dates<-as.vector(data['date_of_purchase'])
class(dates)
#earliest purchase date
min(dates$date_of_purchase)
#most recent purchase chate
max(data$date_of_purchase)
new_data = customers
head(new_data)
row.names(new_data) = new_data$customer_id
new_data$customer_id = NULL
head(new_data)
row.names(new_data) = new_data$customer_id
new_data$customer_id = NULL
head(new_data)
View(new_data)
new_data = customers
View(new_data)
row.names(new_data) = new_data$customer_id
View(new_data)
new_data$customer_id = NULL
View(new_data)
Kloutscores1 <- read.table("~/Documents/R/Kloutscores1.csv", quote="\"", comment.char="")
View(Kloutscores1)
`colnames<-`(Kloutscores1$V1)
`colnames<-`(Kloutscores1)
rownames(Kloutscores1) <- c(“Granny”)
rownames(Kloutscores1) <- “Granny”
rownames(Kloutscores1) <- Granny
rownames(Kloutscores1)
colnames(Kloutscores1)
colnames(Kloutscores1)[1]<-"score"
colnames(Kloutscores1)
colnames(Kloutscores1)=Kloutscores1$score
Kloutscores1$score=NULL
colnames(Kloutscores1)
View(Kloutscores1)
Kloutscores1 <- read.table("~/Documents/R/Kloutscores1.csv", quote="\"", comment.char="")
View(Kloutscores1)
list(Kloutscores1$V1)
new_list<-list(Kloutscores1$V1)
sum(new_list)
library(devtools)
install_version("colorspace", "1.2-4")
View(new_data)
new_data$amount = log(new_data$amount)
hist(new_data$amount)
new_data = scale(new_data)
head(new_data)
View(new_data)
5000-400
4600/50
5000*.235
5000*.0235
100-2.35
95+2.35
sample = seq(1, 18417, by = 10)
head(sample)
customers_sample = customers[sample, ]
View(customers_sample)
new_data_sample  = new_data[sample, ]
d = dist(new_data_sample)
d <- dist(as.matrix(mtcars))   # find distance matrix
hc <- hclust(d)                # apply hirarchical clustering
plot(hc)
e<- dist(as.matrix(Kloutscores1))
kloutCluster<-hclust(e)
plot(kloutCluster)
d = dist(new_data_sample)
c = hclust(d, method="ward.D2")
plot(c)
members = cutree(c, k = 9)
members[1:30]
table(members)
aggregate(customers_sample[, 2:4], by = list(members), mean)
z <- dist(mydata, method = "euclidean") # distance matrix
fit <- hclust(z, method="ward")
plot(fit) # display dendogram
groups <- cutree(fit, k=5) # cut tree into 5 clusters
# draw dendogram with red borders around the 5 clusters
rect.hclust(fit, k=5, border="red")
z <- dist(mydata, method = "euclidean") # distance matrix
mydata <- scale(mtcars) # standardize variables
z <- dist(mydata, method = "euclidean") # distance matrix
fit <- hclust(z, method="ward")
plot(fit) # display dendogram
groups <- cutree(fit, k=5) # cut tree into 5 clusters
rect.hclust(fit, k=5, border="red")
plot(c)
table(members)
install.packages("devtools")
install_github("ozagordi/weatherData")
devtools::install_github("ozagordi/weatherData")
end_date="2016-08-27")
weatherdata <- getWeatherForDate("BOS", "2016-08-01",
end_date="2016-08-15")
weatherdata <- getWeatherForDate("BOS", "2016-08-01", end_date="2016-08-15")
library(weatherData)
getWeatherForDate("SEA", "2014-05-05")
dfw_wx <- getWeatherForYear("DFW", 2013)
jax_wx <- getWeatherForYear("JAX", 2016)
city1 <- "ORD"
city2 <- "SFO"
df1 <- getWeatherForYear(city1, 2013)
df2 <- getWeatherForYear(city2, 2013)
getDailyDifferences <- function(df1, df2){
Delta_Means <- df1$Mean_TemperatureF - df2$Mean_TemperatureF
Delta_Max <- df1$Max_TemperatureF - df2$Max_TemperatureF
Delta_Min <- df1$Min_TemperatureF - df2$Min_TemperatureF
diff_df <- data.frame(Date=df1$Date, Delta_Means, Delta_Max, Delta_Min)
return(diff_df)
}
plotDifferences <- function (differences, city1, city2) {
library(reshape2)
m.diff <- melt(differences, id.vars=c("Date"))
p <- ggplot(m.diff, aes(x=Date, y=value)) + geom_point(aes(color=variable)) +
facet_grid(variable ~ .) +geom_hline(yintercept=0)
p <- p + labs(title=paste0("Daily Temperature Differences: ", city1, " minus ",city2))
print(p)
}
differences<- getDailyDifferences(df1, df2)
plotDifferences(differences, city1, city2)
aggregate(customers_sample[, 2:4], by = list(members), mean)
table(members)
aggregate(customers_sample[, 2:4], by = list(members), mean)
# Load text file into local variable called 'data'
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
# Add headers and interpret the last column as a date, extract year of purchase
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$days_since       = as.numeric(difftime(time1 = "2016-01-01",
time2 = data$date_of_purchase,
units = "days"))
library(sqldf)
customers = sqldf("SELECT customer_id,
MIN(days_since) AS 'recency',
COUNT(*) AS 'frequency',
AVG(purchase_amount) AS 'amount'
FROM data GROUP BY 1")
# Copy customer data into new data frame/carbon copy
new_data = customers
row.names(new_data) = new_data$customer_id
new_data$customer_id = NULL
hist(customers$frequency)
hist(new_data$frequency)
new_data$frequency=log(new_data$frequency)
hist(new_data$frequency)
hist(new_data$frequency, y="log of frequency")
hist(new_data$frequency, main="histogram of new_data with log of frequency")
new_data = scale(new_data)
sample = seq(1, 18417, by = 10)
head(sample)
customers_sample = customers[sample, ]
new_data_sample  = new_data[sample, ]
View(new_data_sample)
dim(customers)
# Compute distance metrics on standardized data
d = dist(new_data_sample)
# Perform hierarchical clustering on distance metrics
c = hclust(d, method="ward.D2")
# Plot de dendogram
plot(c)
members = cutree(c, k = 5)
members[1:5]
table(members)
aggregate(customers_sample[, 2:4], by = list(members), mean)
View(new_data_sample)
new_data_sample[c(260,5920)]
new_data_sample[c(260,5920),]
new_data_sample[260,]
new_data_sample[5920,]
new_data_sample["5920"]
new_data_sample[2700,]
table(members)
aggregate(customers_sample[, 2:4], by = list(members), mean)
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$days_since       = as.numeric(difftime(time1 = "2016-01-01",
time2 = data$date_of_purchase,
units = "days"))
library(sqldf)
customers = sqldf("SELECT customer_id,
MIN(days_since) AS 'recency',
COUNT(*) AS 'frequency',
AVG(purchase_amount) AS 'amount'
FROM data GROUP BY 1")
# Copy customer data into new data frame
new_data = customers
row.names(new_data) = new_data$customer_id
new_data$customer_id = NULL
new_data$frequency=log(new_data$frequency)
hist(new_data$frequency, main="histogram of new_data with log of frequency")
new_data = scale(new_data)
sample = seq(1, 18417, by = 10)
head(sample)
customers_sample = customers[sample, ]
new_data_sample  = new_data[sample, ]
d = dist(new_data_sample)
c = hclust(d, method="ward.D2")
plot(c)
members = cutree(c, k = 5)
members[1:5]
table(members)
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$days_since       = as.numeric(difftime(time1 = "2016-01-01",
time2 = data$date_of_purchase,
units = "days"))
library(sqldf)
customers = sqldf("SELECT customer_id,
MIN(days_since) AS 'recency',
COUNT(*) AS 'frequency',
AVG(purchase_amount) AS 'amount'
FROM data GROUP BY 1")
new_data = customers
row.names(new_data) = new_data$customer_id
new_data$customer_id = NULL
View(new_data)
hist(new_data$frequency)
new_data$frequency=log(new_data$frequency)
hist(new_data$frequency, main="histogram of new_data with log of frequency")
new_data = scale(new_data)
sample = seq(1, 18417, by = 10)
head(sample)
customers_sample = customers[sample, ]
new_data_sample  = new_data[sample, ]
d = dist(new_data_sample)
c = hclust(d, method="ward.D2")
plot(c)
members = cutree(c, k = 5)
members[1:30]
table(members)
aggregate(customers_sample[, 2:4], by = list(members), mean)
members = cutree(c, k = 9)
members[1:30]
table(members)
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$days_since       = as.numeric(difftime(time1 = "2016-01-01",
time2 = data$date_of_purchase,
units = "days"))
customers = sqldf("SELECT customer_id,
MIN(days_since) AS 'recency',
COUNT(*) AS 'frequency',
AVG(purchase_amount) AS 'amount'
FROM data GROUP BY 1")
View(data)
new_data = customers
row.names(new_data) = new_data$customer_id
new_data$customer_id = NULL
new_data$amount = log(new_data$amount)
hist(new_data$amount)
hist(new_data$frequency)
new_data$frequency=log(new_data$frequency)
hist(new_data$frequency, main="histogram of new_data with log of frequency")
new_data = scale(new_data)
sample = seq(1, 18417, by = 10)
head(sample)
customers_sample = customers[sample, ]
new_data_sample  = new_data[sample, ]
# Compute distance metrics on standardized data
d = dist(new_data_sample)
# Perform hierarchical clustering on distance metrics
c = hclust(d, method="ward.D2")
# Plot de dendogram
plot(c)
# Cut at 5 segments
members = cutree(c, k = 5)
# Show 30 first customers, frequency table
members[1:30]
table(members)
# Show profile of each segment
aggregate(customers_sample[, 2:4], by = list(members), mean)
new_data_sample[c(260,5920),]
new_data_sample[260,]
View(new_data_sample)
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$year_of_purchase = as.numeric(format(data$date_of_purchase, "%Y"))
data$days_since       = as.numeric(difftime(time1 = "2016-01-01",
time2 = data$date_of_purchase,
units = "days"))
View(data)
library(sqldf)
customers_2015 = sqldf("SELECT customer_id,
MIN(days_since) AS 'recency',
MAX(days_since) AS 'first_purchase',
COUNT(*) AS 'frequency',
AVG(purchase_amount) AS 'amount'
FROM data GROUP BY 1")
View(customers_2015)
customers_2015$segment = ifelse(test = customers_2015$recency > 365*3, yes = "inactive", no = "NA")
table(customers_2015$segment)
aggregate(x = customers_2015[, 2:5], by = list(customers_2015$segment), mean)
customers_2015$segment = ifelse(test = customers_2015$recency > 365*3,
yes = "inactive",
no = ifelse(test = customers_2015$recency > 365*2,
yes = "cold",
no = "NA"))
table(customers_2015$segment)
aggregate(x = customers_2015[, 2:5], by = list(customers_2015$segment), mean)
View(customers_2015)
customers_2015$segment = "NA"
customers_2015$segment[which(customers_2015$recency > 365*3)] = "inactive"
customers_2015$segment[which(customers_2015$recency <= 365*3 & customers_2015$recency > 365*2)] = "cold"
customers_2015$segment[which(customers_2015$recency <= 365*2 & customers_2015$recency > 365*1)] = "warm"
customers_2015$segment[which(customers_2015$recency <= 365)] = "active"
table(customers_2015$segment)
aggregate(x = customers_2015[, 2:5], by = list(customers_2015$segment), mean)
customers_2015$segment = "NA"
customers_2015$segment[which(customers_2015$recency > 365*3)] = "inactive"
customers_2015$segment[which(customers_2015$recency <= 365*3 & customers_2015$recency > 365*2)] = "cold"
customers_2015$segment[which(customers_2015$recency <= 365*2 & customers_2015$recency > 365*1)] = "warm"
customers_2015$segment[which(customers_2015$recency <= 365)] = "active"
customers_2015$segment[which(customers_2015$segment == "warm" & customers_2015$first_purchase <= 365*2)] = "new warm"
customers_2015$segment[which(customers_2015$segment == "warm" & customers_2015$amount < 100)] = "warm low value"
customers_2015$segment[which(customers_2015$segment == "warm" & customers_2015$amount >= 100)] = "warm high value"
customers_2015$segment[which(customers_2015$segment == "active" & customers_2015$first_purchase <= 365)] = "new active"
customers_2015$segment[which(customers_2015$segment == "active" & customers_2015$amount < 100)] = "active low value"
customers_2015$segment[which(customers_2015$segment == "active" & customers_2015$amount >= 100)] = "active high value"
table(customers_2015$segment)
aggregate(x = customers_2015[, 2:5], by = list(customers_2015$segment), mean)
# Re-order factor in a way that makes sense
customers_2015$segment = factor(x = customers_2015$segment, levels = c("inactive", "cold",
"warm high value", "warm low value", "new warm",
"active high value", "active low value", "new active"))
table(customers_2015$segment)
aggregate(x = customers_2015[, 2:5], by = list(customers_2015$segment), mean)
customers_2014 = sqldf("SELECT customer_id,
MIN(days_since) - 365 AS 'recency',
MAX(days_since) - 365 AS 'first_purchase',
COUNT(*) AS 'frequency',
AVG(purchase_amount) AS 'amount'
FROM data
WHERE days_since > 365
GROUP BY 1")
customers_2014$segment = "NA"
customers_2014$segment[which(customers_2014$recency > 365*3)] = "inactive"
customers_2014$segment[which(customers_2014$recency <= 365*3 & customers_2014$recency > 365*2)] = "cold"
customers_2014$segment[which(customers_2014$recency <= 365*2 & customers_2014$recency > 365*1)] = "warm"
customers_2014$segment[which(customers_2014$recency <= 365)] = "active"
customers_2014$segment[which(customers_2014$segment == "warm" & customers_2014$first_purchase <= 365*2)] = "new warm"
customers_2014$segment[which(customers_2014$segment == "warm" & customers_2014$amount < 100)] = "warm low value"
customers_2014$segment[which(customers_2014$segment == "warm" & customers_2014$amount >= 100)] = "warm high value"
customers_2014$segment[which(customers_2014$segment == "active" & customers_2014$first_purchase <= 365)] = "new active"
customers_2014$segment[which(customers_2014$segment == "active" & customers_2014$amount < 100)] = "active low value"
customers_2014$segment[which(customers_2014$segment == "active" & customers_2014$amount >= 100)] = "active high value"
customers_2014$segment = factor(x = customers_2014$segment, levels = c("inactive", "cold",
"warm high value", "warm low value", "new warm",
"active high value", "active low value", "new active"))
# Show segmentation results
table(customers_2014$segment)
pie(table(customers_2014$segment), col = rainbow(24))
aggregate(x = customers_2014[, 2:5], by = list(customers_2014$segment), mean)
revenue_2015 = sqldf("SELECT customer_id, SUM(purchase_amount) AS 'revenue_2015'
FROM data
WHERE year_of_purchase = 2015
GROUP BY 1")
summary(revenue_2015)
actual = merge(customers_2015, revenue_2015, all.x = TRUE)
actual$revenue_2015[is.na(actual$revenue_2015)] = 0
# Show average revenue per customer and per segment
aggregate(x = actual$revenue_2015, by = list(customers_2015$segment), mean)
forward = merge(customers_2014, revenue_2015, all.x = TRUE)
forward$revenue_2015[is.na(forward$revenue_2015)] = 0
# Show average revenue per customer and per segment
r = aggregate(x = forward$revenue_2015, by = list(customers_2014$segment), mean)
print(r)
# Re-order and display results
r = r[order(r$x, decreasing = TRUE), ]
print(r)
barplot(r$x, names.arg = r$Group.1)
View(data)
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
View(data)
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$year_of_purchase = as.numeric(format(data$date_of_purchase, "%Y"))
data$days_since       = as.numeric(difftime(time1 = "2016-01-01",
time2 = data$date_of_purchase,
units = "days"))
View(data)
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
View(data)
data = read.delim(file = 'purchases.txt', header = FALSE, sep = '\t', dec = '.')
View(data)
dim(data)
?dplyr
??dplyr
library(dplyr)
distinct(data)
colnames(data) = c('customer_id', 'purchase_amount', 'date_of_purchase')
data$date_of_purchase = as.Date(data$date_of_purchase, "%Y-%m-%d")
data$days_since       = as.numeric(difftime(time1 = "2016-01-01",
time2 = data$date_of_purchase,
units = "days"))
distinct(data)
View(data)
library("xlsx")
read.xlsx("cleanedRFMData.xlsx", sheetIndex = 1,header = TRUE)
sont<-read.xlsx("cleanedRFMData.xlsx", sheetIndex = 1,header = TRUE)
View(sont)
summary(sont)
str(sont)
sont$date_last_usage = as.Date(sont$date_last_usage, "%Y-%m-%d")
sont$days_since= as.numeric(difftime(time1 = "2016-09-01",
time2 = data$date_last_usage, units                         = "days"))
str(sont)
View(sont)
sont$days_since= as.numeric(difftime(time1 = "2016-09-01",
time2 = data$date_last_usage, units                         = "days"))
sont$days_since= as.numeric(difftime(time1 = "2016-09-01",
time2 = sont$date_last_usage, units                         = "days"))
str(sont)
View(sont)
library(sqldf)
customers = sqldf("SELECT account_id,
MIN(days_since) AS 'recency',
COUNT(*) AS 'frequency',
AVG(amount) AS 'amount'
FROM sont GROUP BY 1")
head(sont)
summary(sont)
hist(customers$recency)
hist(customers$frequency)
hist(customers$amount)
hist(customers$amount, breaks = 100)
hist(customers$amount, breaks = 200)
new_data = customers
head(new_data)
row.names(new_data) = new_data$customer_id
new_data$customer_id = NULL
head(new_data)
View(new_data)
head(new_data)
row.names(new_data) = new_data$account_id
new_data$account_id = NULL
head(new_data)
View(new_data)
new_data$amount = log(new_data$amount)
hist(new_data$amount)
new_data = scale(new_data)
head(new_data)
BullRiders<-read.csv("BullRiders.csv")
View(BullRiders)
library(lattice)
library(datasets)
xyplot(Ozone ~ Wind, data=airquality)
set.seed(10)
x<-rnorm(100)
f<-rep(0:1, each=50)
y<-x + f - f * x + rnorm(100, sd=.5)
f<-factor(f, labels = c("Group 1", "Group 2"))
xyplot(y ~ x | f, layout = c(2,1))
xyplot (y ~ x | f, panel = function(x,y,...){
panel.xyplot(x,y,...)##first call the default panel function for xyplot
panel.lmline(x,y, col=2) ##overlay a simple regression line
})
library(hexbin)
x <- rnorm(1000)
y <- rnorm(1000)
bin<-hexbin(x, y, xbins=50)
plot(bin, main="Hexagonal Binning")
piq <- read.csv("~/Documents/R/piq.csv")
View(piq)
fit <- lm(y ~ x1 + x2 + x3, data=piq)
fit <- lm(y ~ "Brain" + "Height" + "Weight", data=piq)
fit <- lm("PIQ" ~ "Brain" + "Height" + "Weight", data=piq)
fit <- lm(PIQ ~ Brain + Height + Weight, data=piq)
summary(fit) # show results
pairs(~PIQ+Brain+Height+Weight,data=piq,
main=" Scatterplot Matrix")
?attach
library(scatterplot3d)
install.packages("scatterplot3d")
library(scatterplot3d)
scatterplot3d(~PIQ+Brain+Height+Weight,data=piq, main="3D Scatterplot")
Scatterplot Matrix
library(scatterplot3d)
scatterplot3d(PIQ,Brain,Height,Weight,data=piq, main="3D Scatterplot")
attach(piq)
scatterplot3d(PIQ,Brain,Height,Weight,data=piq, main="3D Scatterplot")
library(scatterplot3d)
attach(piq)
scatterplot3d(PIQ,Brain,Height,Weight, main="3D Scatterplot")
plot3d(PIQ,Brain,Height,Weight, main="Spinning Scatterplot")
library(rgl)
plot3d(PIQ,Brain,Height,Weight, main="Spinning Scatterplot")
library(rgl)
plot3d(PIQ,Brain,Height,Weight)
